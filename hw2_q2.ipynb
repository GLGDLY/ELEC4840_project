{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from monai.utils import first, set_determinism\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    AsDiscreted,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    SaveImaged,\n",
    "    ScaleIntensityRanged,\n",
    "    RandRotated,\n",
    "    RandZoomd,\n",
    "    RandGaussianNoised,\n",
    "    RandAdjustContrastd,\n",
    "    Spacingd,\n",
    "    Invertd,\n",
    ")\n",
    "from monai.handlers.utils import from_engine\n",
    "from monai.networks.nets import UNet\n",
    "from monai.networks.layers import Norm\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.losses import DiceLoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import CacheDataset, DataLoader, Dataset, decollate_batch\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set train/validation/test data filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./dataset\"\n",
    "train_images = sorted(glob.glob(os.path.join(data_dir,\"train\" ,\"image\", \"*.nii.gz\")))\n",
    "train_labels = sorted(glob.glob(os.path.join(data_dir,\"train\" , \"mask\", \"*.nii.gz\")))\n",
    "train_data_dicts = [{\"image\": image_name, \"label\": label_name} for image_name, label_name in zip(train_images, train_labels)]\n",
    "\n",
    "val_images = sorted(glob.glob(os.path.join(data_dir,\"val\" ,\"image\", \"*.nii.gz\")))\n",
    "val_labels = sorted(glob.glob(os.path.join(data_dir,\"val\" , \"mask\", \"*.nii.gz\")))\n",
    "val_data_dicts = [{\"image\": image_name, \"label\": label_name} for image_name, label_name in zip(val_images, val_labels)]\n",
    "\n",
    "test_images = sorted(glob.glob(os.path.join(data_dir,\"test\" ,\"image\", \"*.nii.gz\")))\n",
    "test_labels = sorted(glob.glob(os.path.join(data_dir,\"test\" , \"mask\", \"*.nii.gz\")))\n",
    "test_data_dicts = [{\"image\": image_name, \"label\": label_name} for image_name, label_name in zip(test_images, test_labels)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup data augmentation\n",
    "\n",
    "For data augmentation, here are the basic requirements:\n",
    "\n",
    "1. `LoadImaged` loads the spleen CT images and labels from NIfTI format files.\n",
    "1. `EnsureChannelFirstd` ensures the original data to construct \"channel first\" shape.\n",
    "1. `ScaleIntensityRanged` clips the CT's data format, HU value, into a certain range (-57,164) and normalize it to (0,1)\n",
    "1. `CropForegroundd` removes all zero borders to focus on the valid body area of the images and labels.\n",
    "1. `RandCropByPosNegLabeld` randomly crop patch samples from big image based on pos / neg ratio.  \n",
    "The image centers of negative samples must be in valid body area.\n",
    "\n",
    "You can try more data augmentation techniques to further improve the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leung\\Desktop\\HKUST\\ELEC4840_project\\venv\\lib\\site-packages\\monai\\utils\\deprecate_utils.py:321: FutureWarning: monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "  warn_deprecated(argname, msg, warning_category)\n"
     ]
    }
   ],
   "source": [
    "train_transforms = Compose([\n",
    "    LoadImaged(keys=[\"image\", \"label\"]),\n",
    "    EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "    ScaleIntensityRanged(keys=[\"image\"], a_min=-57, a_max=164, b_min=0.0, b_max=1.0, clip=True),\n",
    "    CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "    RandRotated(keys=[\"image\", \"label\"], prob=0.5, range_x=0.3, range_y=0.3, range_z=0.3),\n",
    "    RandZoomd(keys=[\"image\", \"label\"], prob=0.5, min_zoom=0.8, max_zoom=1.2),\n",
    "    RandGaussianNoised(keys=\"image\", prob=0.2, mean=0.0, std=0.05),\n",
    "    RandAdjustContrastd(keys=\"image\", prob=0.3, gamma=(0.7, 1.3)),\n",
    "    RandCropByPosNegLabeld(\n",
    "        keys=[\"image\", \"label\"],\n",
    "        label_key=\"label\",\n",
    "        spatial_size=(32, 32, 16),\n",
    "        pos=1,\n",
    "        neg=1,\n",
    "        num_samples=4,\n",
    "        image_key=\"image\"\n",
    "    ),\n",
    "    Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\")\n",
    "])\n",
    "\n",
    "val_transforms = Compose([\n",
    "    LoadImaged(keys=[\"image\", \"label\"]),\n",
    "    EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "    ScaleIntensityRanged(keys=[\"image\"], a_min=-57, a_max=164, b_min=0.0, b_max=1.0, clip=True),\n",
    "    CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "    Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 12/12 [00:05<00:00,  2.19it/s]\n",
      "Loading dataset: 100%|██████████| 4/4 [00:01<00:00,  2.35it/s]\n",
      "Loading dataset: 100%|██████████| 8/8 [00:06<00:00,  1.15it/s]\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from monai.data import CacheDataset, list_data_collate\n",
    "\n",
    "# class CT_Dataset(Dataset):\n",
    "#     def __init__(self, dataset_path, transform=None,split='test'):\n",
    "#         self.dataset_path = dataset_path\n",
    "#         self.transform = transform\n",
    "#         self.split = split\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.dataset_path)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         data = self.dataset_path[idx]\n",
    "#         image = nib.load(data['image'])\n",
    "#         label = nib.load(data['label'])\n",
    "#         image = image.get_fdata()\n",
    "#         label = label.get_fdata()\n",
    "#         if self.transform:\n",
    "#             image, label = self.transform(image, label)\n",
    "#         return image, label\n",
    "        \n",
    "\n",
    "# train_files = train_data_dicts\n",
    "# val_files = val_data_dicts\n",
    "# test_files = test_data_dicts\n",
    "# test_transforms = val_transforms\n",
    "\n",
    "# # here we don't cache any data in case out of memory issue\n",
    "# train_ds = CT_Dataset(train_files,train_transforms,split='train')\n",
    "# train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=4)\n",
    "# val_ds = CT_Dataset(val_files,val_transforms,split='val')\n",
    "# val_loader = DataLoader(val_ds, batch_size=1, shuffle=False, num_workers=4)\n",
    "# test_ds = CT_Dataset(test_files,test_transforms,split='test')\n",
    "# test_loader = DataLoader(test_ds, batch_size=2, shuffle=True, num_workers=4)\n",
    "# val_ds = CT_Dataset(val_files,val_transforms,split='val')\n",
    "# val_loader = DataLoader(val_ds, batch_size=1, shuffle=False, num_workers=4)\n",
    "train_ds = CacheDataset(data=train_data_dicts, transform=train_transforms, cache_rate=0.5, num_workers=4)\n",
    "train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=4, collate_fn=list_data_collate)\n",
    "\n",
    "val_ds = CacheDataset(data=val_data_dicts, transform=val_transforms, cache_rate=0.5, num_workers=4)\n",
    "val_loader = DataLoader(val_ds, batch_size=1, shuffle=False, num_workers=4, collate_fn=list_data_collate)\n",
    "\n",
    "test_ds = CacheDataset(data=test_data_dicts, transform=val_transforms)\n",
    "test_loader = DataLoader(test_ds, batch_size=1, shuffle=False, num_workers=4, collate_fn=list_data_collate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement a 3D UNet for segmentation task\n",
    "\n",
    "We give a possible network structure here, and you can modify it for a stronger performance.\n",
    "\n",
    "In the block ```double_conv```, you can implement the following structure：\n",
    "\n",
    "| Layer |\n",
    "|-------|\n",
    "| Conv3d |\n",
    "| BatchNorm3d |\n",
    "| PReLU |\n",
    "| Conv3d |\n",
    "| BatchNorm3d |\n",
    "| PReLU |\n",
    "\n",
    "\n",
    "In the overall UNet structure, you can implement the following structure. ```conv_down``` and ```conv_up``` refers to the function block you defined above.\n",
    "\n",
    "| Layer | Input Channel | Output Channel |\n",
    "|-------|-------------|--------------|\n",
    "| conv_down1 | 1 | 16 |\n",
    "| maxpool | 16 | 16 |\n",
    "| conv_down2 | 16 | 32 |\n",
    "| maxpool | 32 | 32 |\n",
    "| conv_down3 | 32 | 64 |\n",
    "| maxpool | 64 | 64 |\n",
    "| conv_down4 | 64 | 128 |\n",
    "| maxpool | 128 | 128 |\n",
    "| conv_down5 | 128 | 256 |\n",
    "| upsample | 256 | 256 |\n",
    "| conv_up4 | 128+256 | 128 |\n",
    "| upsample | 128 | 128 |\n",
    "| conv_up3 | 64+128 | 64 |\n",
    "| upsample | 64 | 32 |\n",
    "| conv_up4 | 32+64 | 32 |\n",
    "| upsample | 32 | 32 |\n",
    "| conv_up4 | 16+32 | 16 |\n",
    "| conv_out | 16 | 2 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def double_conv(in_channels, out_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv3d(in_channels, out_channels, 3, padding=1),\n",
    "        nn.BatchNorm3d(out_channels),\n",
    "        nn.PReLU(),\n",
    "        nn.Conv3d(out_channels, out_channels, 3, padding=1),\n",
    "        nn.BatchNorm3d(out_channels),\n",
    "        nn.PReLU()\n",
    "    )\n",
    "\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dconv_down1 = double_conv(1, 16)\n",
    "        self.dconv_down2 = double_conv(16, 32)\n",
    "        self.dconv_down3 = double_conv(32, 64)\n",
    "        self.dconv_down4 = double_conv(64, 128)\n",
    "        self.dconv_down5 = double_conv(128, 256)\n",
    "        \n",
    "        self.maxpool = nn.MaxPool3d(2)\n",
    "        \n",
    "        self.upsample4 = nn.ConvTranspose3d(256, 256, kernel_size=2, stride=2)\n",
    "        self.dconv_up4 = double_conv(128 + 256, 128)\n",
    "        \n",
    "        self.upsample3 = nn.ConvTranspose3d(128, 128, kernel_size=2, stride=2)\n",
    "        self.dconv_up3 = double_conv(64 + 128, 64)\n",
    "        \n",
    "        self.upsample2 = nn.ConvTranspose3d(64, 64, kernel_size=2, stride=2)\n",
    "        self.dconv_up2 = double_conv(32 + 64, 32)\n",
    "        \n",
    "        self.upsample1 = nn.ConvTranspose3d(32, 32, kernel_size=2, stride=2)\n",
    "        self.dconv_up1 = double_conv(16 + 32, 16)\n",
    "        \n",
    "        self.conv_last = nn.Conv3d(16, 2, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        conv1 = self.dconv_down1(x)\n",
    "        x = self.maxpool(conv1)\n",
    "        \n",
    "        conv2 = self.dconv_down2(x)\n",
    "        x = self.maxpool(conv2)\n",
    "        \n",
    "        conv3 = self.dconv_down3(x)\n",
    "        x = self.maxpool(conv3)\n",
    "        \n",
    "        conv4 = self.dconv_down4(x)\n",
    "        x = self.maxpool(conv4)\n",
    "        \n",
    "        x = self.dconv_down5(x)\n",
    "        \n",
    "        x = self.upsample4(x)\n",
    "        x = torch.cat([x, conv4], dim=1)\n",
    "        x = self.dconv_up4(x)\n",
    "        \n",
    "        x = self.upsample3(x)\n",
    "        x = torch.cat([x, conv3], dim=1)\n",
    "        x = self.dconv_up3(x)\n",
    "        \n",
    "        x = self.upsample2(x)\n",
    "        x = torch.cat([x, conv2], dim=1)\n",
    "        x = self.dconv_up2(x)\n",
    "        \n",
    "        x = self.upsample1(x)\n",
    "        x = torch.cat([x, conv1], dim=1)\n",
    "        x = self.dconv_up1(x)\n",
    "        \n",
    "        out = self.conv_last(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model, Loss, Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class _CELoss(torch.nn.CrossEntropyLoss):\n",
    "    def forward(self, pred, target):\n",
    "        return super().forward(pred, target.squeeze(1).long())\n",
    "    \n",
    "\n",
    "class CombinedLoss(torch.nn.Module):\n",
    "    def __init__(self, weights_dice=0.5, weights_ce=0.5):\n",
    "        super().__init__()\n",
    "        self.dice = DiceLoss(to_onehot_y=True, softmax=True, include_background=False)\n",
    "        self.ce = _CELoss()\n",
    "        self.weights_dice = weights_dice\n",
    "        self.weights_ce = weights_ce\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        return self.dice(pred, target) * self.weights_dice + self.ce(pred, target) * self.weights_ce\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device.type == \"cuda\":\n",
    "    print(\"Using GPU\")\n",
    "model = UNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-3, weight_decay=1e-5)\n",
    "dice_metric = DiceMetric(include_background=False, reduction=\"mean\")\n",
    "\n",
    "# loss_function = DiceLoss(to_onehot_y=True, softmax=True, include_background=False)\n",
    "loss_fns = {\n",
    "    # \"Dice\": DiceLoss(to_onehot_y=True, softmax=True, include_background=False),\n",
    "    # \"CE\": _CELoss(),\n",
    "    \"Combined_1_1_300_epoch\": CombinedLoss(weights_dice=1.0, weights_ce=1.0),\n",
    "    \"Combined_7_3_300_epoch\": CombinedLoss(weights_dice=0.7, weights_ce=0.3),\n",
    "    \"Combined_3_7_300_epoch\": CombinedLoss(weights_dice=0.3, weights_ce=0.7),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define your training/val/test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Combined_1_1_300_epoch loss\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78cc209417004b00a5fbd2dafefc9483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 1/200:   0%|          | 0/13 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     25\u001b[0m dice_metric\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_data \u001b[38;5;129;01min\u001b[39;00m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     28\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m batch_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     29\u001b[0m     labels \u001b[38;5;241m=\u001b[39m batch_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\Users\\leung\\Desktop\\HKUST\\ELEC4840_project\\venv\\lib\\site-packages\\tqdm\\notebook.py:250\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    249\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[1;32m--> 250\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[0;32m    251\u001b[0m         \u001b[38;5;66;03m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m    253\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\leung\\Desktop\\HKUST\\ELEC4840_project\\venv\\lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\leung\\Desktop\\HKUST\\ELEC4840_project\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:491\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    490\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 491\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\leung\\Desktop\\HKUST\\ELEC4840_project\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:422\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    421\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 422\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\leung\\Desktop\\HKUST\\ELEC4840_project\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1146\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1139\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1140\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1141\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1142\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1144\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1146\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1148\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from monai.metrics import DiceMetric, HausdorffDistanceMetric, MeanIoU, SurfaceDistanceMetric\n",
    "from monai.data import MetaTensor\n",
    "from tqdm.notebook import tqdm\n",
    "from monai.transforms import EnsureTyped\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "for loss_name, loss_fn in loss_fns.items():\n",
    "    print(f\"Training with {loss_name} loss\")\n",
    "    writer = SummaryWriter(f\"runs/{loss_name}_{datetime.now().strftime('%Y%m%d-%H%M%S')}\")\n",
    "\n",
    "    max_epochs = 200\n",
    "    best_metric = -1\n",
    "    best_metric_epoch = -1\n",
    "    train_loss_values = []\n",
    "    train_dice_values = []\n",
    "    val_loss_values = []\n",
    "    val_dice_values = []\n",
    "    post_pred = Compose([AsDiscrete(argmax=True, to_onehot=2)])\n",
    "    post_label = Compose([AsDiscrete(to_onehot=2)])\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        dice_metric.reset()\n",
    "        \n",
    "        for batch_data in tqdm(train_loader, desc=f\"Training Epoch {epoch + 1}/{max_epochs}\", unit=\"batch\"):\n",
    "            inputs = batch_data[\"image\"].to(device)\n",
    "            labels = batch_data[\"label\"].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_outputs = [post_pred(i) for i in decollate_batch(outputs)]\n",
    "            train_labels = [post_label(i) for i in decollate_batch(labels)]\n",
    "\n",
    "            dice_metric(y_pred=train_outputs, y=train_labels)\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        epoch_dice = dice_metric.aggregate().item()\n",
    "        \n",
    "        train_loss_values.append(train_loss)\n",
    "        train_dice_values.append(epoch_dice)\n",
    "        writer.add_scalar(\"Loss/train\", train_loss, epoch)\n",
    "        writer.add_scalar(\"Dice/train\", epoch_dice, epoch)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{max_epochs}, Loss: {train_loss:.4f}, Dice: {epoch_dice:.4f}\")\n",
    "\n",
    "        # Val\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        dice_metric.reset()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for val_data in tqdm(val_loader, desc=\"Validation\", unit=\"batch\"):\n",
    "                val_images = val_data[\"image\"].to(device)\n",
    "                val_labels = val_data[\"label\"].to(device)\n",
    "                \n",
    "                val_outputs = sliding_window_inference(val_images, (32, 32, 16), 4, model)\n",
    "            \n",
    "                loss = loss_fn(val_outputs, val_labels)\n",
    "\n",
    "                val_outputs = [post_pred(i) for i in decollate_batch(val_outputs)]\n",
    "                val_labels = [post_label(i) for i in decollate_batch(val_labels)]\n",
    "\n",
    "                dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "            val_dice = dice_metric.aggregate().item()\n",
    "            val_loss /= len(val_loader)\n",
    "            val_loss_values.append(val_loss)\n",
    "            val_dice_values.append(val_dice)\n",
    "            writer.add_scalar(\"Loss/val\", val_loss, epoch)\n",
    "            writer.add_scalar(\"Dice/val\", val_dice, epoch)\n",
    "            \n",
    "            if val_dice > best_metric:\n",
    "                best_metric = val_dice\n",
    "                best_metric_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(), f\"best_model_{loss_name}.pth\")\n",
    "                \n",
    "            print(f\"Validation - Loss: {val_loss:.4f}, Dice: {val_dice:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference and Report performance on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with Combined_1_1_300_epoch loss\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bce3b1def8542498bc70789459d0d60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/8 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-12 23:11:25,309 INFO image_writer.py:197 - writing: output\\Combined_1_1_300_epoch\\spleen_52_pred.nii.gz\n",
      "2025-05-12 23:11:35,522 INFO image_writer.py:197 - writing: output\\Combined_1_1_300_epoch\\spleen_53_pred.nii.gz\n",
      "2025-05-12 23:11:38,225 INFO image_writer.py:197 - writing: output\\Combined_1_1_300_epoch\\spleen_56_pred.nii.gz\n",
      "2025-05-12 23:11:40,725 INFO image_writer.py:197 - writing: output\\Combined_1_1_300_epoch\\spleen_59_pred.nii.gz\n",
      "2025-05-12 23:11:46,551 INFO image_writer.py:197 - writing: output\\Combined_1_1_300_epoch\\spleen_60_pred.nii.gz\n",
      "2025-05-12 23:11:54,676 INFO image_writer.py:197 - writing: output\\Combined_1_1_300_epoch\\spleen_61_pred.nii.gz\n",
      "2025-05-12 23:11:59,393 INFO image_writer.py:197 - writing: output\\Combined_1_1_300_epoch\\spleen_62_pred.nii.gz\n",
      "2025-05-12 23:12:04,257 INFO image_writer.py:197 - writing: output\\Combined_1_1_300_epoch\\spleen_63_pred.nii.gz\n",
      "\n",
      "Test Results for Combined_1_1_300_epoch loss\n",
      "Dice Score: 0.7022\n",
      "Jaccard Index: 0.5649\n",
      "95% Hausdorff Distance: 187.3684\n",
      "Average Surface Distance: 30.5600\n",
      "Testing with Combined_7_3_300_epoch loss\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0233360a507d43ef84b4b9537b898daa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/8 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-12 23:12:20,179 INFO image_writer.py:197 - writing: output\\Combined_7_3_300_epoch\\spleen_52_pred.nii.gz\n",
      "2025-05-12 23:12:28,551 INFO image_writer.py:197 - writing: output\\Combined_7_3_300_epoch\\spleen_53_pred.nii.gz\n",
      "2025-05-12 23:12:30,971 INFO image_writer.py:197 - writing: output\\Combined_7_3_300_epoch\\spleen_56_pred.nii.gz\n",
      "2025-05-12 23:12:34,901 INFO image_writer.py:197 - writing: output\\Combined_7_3_300_epoch\\spleen_59_pred.nii.gz\n",
      "2025-05-12 23:12:44,070 INFO image_writer.py:197 - writing: output\\Combined_7_3_300_epoch\\spleen_60_pred.nii.gz\n",
      "2025-05-12 23:12:53,956 INFO image_writer.py:197 - writing: output\\Combined_7_3_300_epoch\\spleen_61_pred.nii.gz\n",
      "2025-05-12 23:12:59,811 INFO image_writer.py:197 - writing: output\\Combined_7_3_300_epoch\\spleen_62_pred.nii.gz\n",
      "2025-05-12 23:13:05,738 INFO image_writer.py:197 - writing: output\\Combined_7_3_300_epoch\\spleen_63_pred.nii.gz\n",
      "\n",
      "Test Results for Combined_7_3_300_epoch loss\n",
      "Dice Score: 0.7350\n",
      "Jaccard Index: 0.6051\n",
      "95% Hausdorff Distance: 195.1658\n",
      "Average Surface Distance: 29.3420\n",
      "Testing with Combined_3_7_300_epoch loss\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1000a4adda3a4348bbb3e4f044c610eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/8 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-12 23:13:18,598 INFO image_writer.py:197 - writing: output\\Combined_3_7_300_epoch\\spleen_52_pred.nii.gz\n",
      "2025-05-12 23:13:25,249 INFO image_writer.py:197 - writing: output\\Combined_3_7_300_epoch\\spleen_53_pred.nii.gz\n",
      "2025-05-12 23:13:27,577 INFO image_writer.py:197 - writing: output\\Combined_3_7_300_epoch\\spleen_56_pred.nii.gz\n",
      "2025-05-12 23:13:29,182 INFO image_writer.py:197 - writing: output\\Combined_3_7_300_epoch\\spleen_59_pred.nii.gz\n",
      "2025-05-12 23:13:36,142 INFO image_writer.py:197 - writing: output\\Combined_3_7_300_epoch\\spleen_60_pred.nii.gz\n",
      "2025-05-12 23:13:44,750 INFO image_writer.py:197 - writing: output\\Combined_3_7_300_epoch\\spleen_61_pred.nii.gz\n",
      "2025-05-12 23:13:50,422 INFO image_writer.py:197 - writing: output\\Combined_3_7_300_epoch\\spleen_62_pred.nii.gz\n",
      "2025-05-12 23:13:55,255 INFO image_writer.py:197 - writing: output\\Combined_3_7_300_epoch\\spleen_63_pred.nii.gz\n",
      "\n",
      "Test Results for Combined_3_7_300_epoch loss\n",
      "Dice Score: 0.7503\n",
      "Jaccard Index: 0.6224\n",
      "95% Hausdorff Distance: 152.0586\n",
      "Average Surface Distance: 20.6887\n"
     ]
    }
   ],
   "source": [
    "for loss_name, loss_fn in loss_fns.items():\n",
    "    print(f\"Testing with {loss_name} loss\")\n",
    "\n",
    "    post_pred_save = Compose([\n",
    "        AsDiscreted(keys=\"pred\", argmax=True),\n",
    "        EnsureTyped(keys=\"pred\", data_type=\"tensor\")\n",
    "    ])\n",
    "\n",
    "    model.load_state_dict(torch.load(f\"best_model_{loss_name}.pth\"))\n",
    "    model.eval()\n",
    "    post_trans = Compose([\n",
    "        EnsureTyped(keys=\"pred\", data_type=\"tensor\"),\n",
    "        Invertd(\n",
    "            keys=\"pred\",\n",
    "            transform=val_transforms, \n",
    "            orig_keys=\"image\",\n",
    "            nearest_interp=False,\n",
    "            to_tensor=True,\n",
    "        ),\n",
    "        SaveImaged(\n",
    "            keys=\"pred\",\n",
    "            meta_keys=\"image_meta_dict\",\n",
    "            output_dir=f\"./output/{loss_name}\",\n",
    "            output_postfix=\"pred\",\n",
    "            output_ext=\".nii.gz\",\n",
    "            resample=False,\n",
    "            separate_folder=False,\n",
    "        )\n",
    "    ])\n",
    "    os.makedirs(f\"./output/{loss_name}\", exist_ok=True)\n",
    "\n",
    "    dice_metric = DiceMetric(include_background=False, reduction=\"mean\")\n",
    "    jaccard_metric = MeanIoU(include_background=False, reduction=\"mean\")\n",
    "    hd95_metric = HausdorffDistanceMetric(percentile=95, include_background=False)\n",
    "    asd_metric = SurfaceDistanceMetric(include_background=False, symmetric=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for test_data in tqdm(test_loader, desc=\"Testing\", unit=\"batch\"):\n",
    "            test_image = test_data[\"image\"].to(device)\n",
    "            test_label = test_data[\"label\"].to(device)\n",
    "            \n",
    "            test_output = sliding_window_inference(test_image, (64, 64, 16), 16, model)\n",
    "\n",
    "            test_output_save = [post_pred_save({\"pred\": i}) for i in decollate_batch(test_output)]\n",
    "            test_output = [post_pred(i) for i in decollate_batch(test_output)]\n",
    "            test_labels = [post_label(i) for i in decollate_batch(test_label)]\n",
    "            \n",
    "            dice_metric(y_pred=test_output, y=test_labels)\n",
    "            jaccard_metric(y_pred=test_output, y=test_labels)\n",
    "            hd95_metric(y_pred=test_output, y=test_labels)\n",
    "            asd_metric(y_pred=test_output, y=test_labels)\n",
    "\n",
    "            for i in range(len(test_output_save)):\n",
    "                sample_data = {\n",
    "                    \"image\": test_data[\"image\"][i],\n",
    "                    \"pred\": MetaTensor(test_output_save[i][\"pred\"], meta=test_data[\"image\"][i].meta)\n",
    "                }\n",
    "                post_trans(sample_data)\n",
    "\n",
    "    dice_score = dice_metric.aggregate().item()\n",
    "    jaccard_score = jaccard_metric.aggregate().item()\n",
    "    hd95_score = hd95_metric.aggregate().item()\n",
    "    asd_score = asd_metric.aggregate().item()\n",
    "\n",
    "    print(f\"\\nTest Results for {loss_name} loss\")\n",
    "    print(f\"Dice Score: {dice_score:.4f}\")\n",
    "    print(f\"Jaccard Index: {jaccard_score:.4f}\")\n",
    "    print(f\"95% Hausdorff Distance: {hd95_score:.4f}\")\n",
    "    print(f\"Average Surface Distance: {asd_score:.4f}\")\n",
    "\n",
    "\n",
    "    # just in case I want to run again and forgot the reset the things\n",
    "    dice_metric.reset()\n",
    "    jaccard_metric.reset()\n",
    "    hd95_metric.reset()\n",
    "    asd_metric.reset()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
